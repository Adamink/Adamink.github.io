<?xml version="1.0" encoding="utf-8"?>
<search> 
  
    
    <entry>
      <title>Sph Water Simulation</title>
      <link href="/sphwatersimulation/"/>
      <url>/sphwatersimulation/</url>
      <content type="html"><![CDATA[<p><img src="images/sph_demo.gif" alt=""></p><p>This repository is a course project of Physically-Based Simulation in Computer Graphics, ETH Zurich, Fall 2020.</p><p>The project is a collaborative work from <a href="https://github.com/GeCao" target="_blank" rel="noopener">Ge Cao</a>, <a href="https://github.com/Adamink" target="_blank" rel="noopener">Xiao Wu</a>, <a href="https://github.com/FrauSong" target="_blank" rel="noopener">Mingyang Song</a>.</p><p>The demo video is available at <a href="https://youtu.be/wf_0VI8c-Rg" target="_blank" rel="noopener">Youtube</a>.</p><p>Features:</p><ul><li>Particle-based fluid simulation with SPH method</li><li>Iterative SESPH</li><li>Coupling liquid simulation with rigid body (the wheel)</li><li>Dambreak scene &amp; Waterwheel scene</li><li>Particles import &amp; export in <code>ply</code> and <code>cfg</code> format</li><li>Multiple ways of visualization using <a href="http://www.ovito.org/" target="_blank" rel="noopener">OVITO</a>, <a href="https://www.opengl.org/resources/libraries/glut/" target="_blank" rel="noopener">OpenGL/GLUT</a> and <a href="https://www.blender.org/" target="_blank" rel="noopener">blender</a></li><li>Surface reconstruction using <a href="https://github.com/w1th0utnam3/splashsurf" target="_blank" rel="noopener">splashsurf</a></li><li>Multithreading for accelerating simulation using <a href="https://www.openmp.org/" target="_blank" rel="noopener">OpenMP</a></li><li>Rendered with GPU accelerated ray-tracing using <a href="https://www.cycles-renderer.org/" target="_blank" rel="noopener">Cycles</a> </li></ul><h2 id="Install-amp-Run"><a href="#Install-amp-Run" class="headerlink" title="Install &amp; Run"></a>Install &amp; Run</h2><p>The installation has only been tested on Ubuntu for now. The project is built with <a href="https://cmake.org/" target="_blank" rel="noopener">CMake</a>. Before installation, please make sure CMake is installed. The project also depends on OpenGL/GLUT, please use the following command to install dependencies.<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install libglu1-mesa-dev freeglut3-dev mesa-common-dev libx11-dev libxi-dev</span><br></pre></td></tr></table></figure></p><p>To build the project, run the following command in the project folder.<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">mkdir build</span><br><span class="line">cd build</span><br><span class="line">cmake ..</span><br><span class="line">make</span><br></pre></td></tr></table></figure></p><p>Then, type <code>./SphWaterSimulation</code> to run the simulation.</p><h2 id="Render"><a href="#Render" class="headerlink" title="Render"></a>Render</h2><p>For further rendering, we use <a href="https://github.com/w1th0utnam3/splashsurf" target="_blank" rel="noopener">splashsurf</a> to reconstruct the liquid surface, and use <a href="https://www.blender.org/" target="_blank" rel="noopener">blender</a> to render the scene. When importing sequence of .obj files into blender, please refer to plugin <a href="https://github.com/neverhood311/Stop-motion-OBJ" target="_blank" rel="noopener">stop motion obj</a> for blender.</p><p>To install relevant packages, please refer to <code>scripts/install_utilities.sh</code></p><p>After installation, use <code>python3 ./scripts/construct_surface.py</code> to construct liquid surface.</p><p>We also upload our blender file to Google Drive for future reference <a href="https://drive.google.com/drive/folders/1yZUP7o5rQNcQyGSNhPJRxcLfqKRuhjfM?usp=sharing" target="_blank" rel="noopener">Link</a>.</p><h2 id="Config"><a href="#Config" class="headerlink" title="Config"></a>Config</h2><p>The config file is <code>SphWaterSimulation/constants.h</code>. To disable visualization, change variable <code>IF_VISUALIZE</code> to <code>false</code>. To disable rigid body(the wheel), change <code>kUseRigidBody</code> to <code>false</code>.</p>]]></content>
      
      
        <tags>
            
            <tag> projects </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Multipath Event-Based Network for Low-Power Human Action Recognition</title>
      <link href="/eventbasedaction/"/>
      <url>/eventbasedaction/</url>
      <content type="html"><![CDATA[<p><br>  <img src="images/eventbasedaction/figure1.png" width="500"><br></p><p><a href="https://ieeexplore.ieee.org/document/9221355" target="_blank" rel="noopener">[PDF]</a></p><p>The implementation of Multipath Event-Based Network for Low-Power Human Action Recognition (WFIoT 2020). </p><h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>Event-based cameras are bio-inspired sensors capturing asynchronous per-pixel brightness changes (events), which have the advantages of high temporal resolution and low power consumption compared with traditional frame-based cameras. </p><p>We propose a multipath deep neural network for action recognition<br>based on event camera outputs. Extensive experiments verify the effectiveness of the proposed model with a recognition accuracy of 85.91% on the DHP19 dataset.</p><p><br>  <img src="images/eventbasedaction/figure1_3.png" width="500"><br></p><h1 id="Installation"><a href="#Installation" class="headerlink" title="Installation"></a>Installation</h1><p>This repository uses PyTorch, which can be installed by following commands.<br><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda install pytorch torchvision torchaudio cudatoolkit=10.2 -c pytorch</span><br></pre></td></tr></table></figure></p><h1 id="Dataset"><a href="#Dataset" class="headerlink" title="Dataset"></a>Dataset</h1><h2 id="Offical-Dataset"><a href="#Offical-Dataset" class="headerlink" title="Offical Dataset"></a>Offical Dataset</h2><p>The offical DHP19 dataset is avaiable <a href="https://sites.google.com/view/dhp19/home" target="_blank" rel="noopener">here</a>.</p><h2 id="Preprocessing"><a href="#Preprocessing" class="headerlink" title="Preprocessing"></a>Preprocessing</h2><p>After downloading, Matlab scripts are used to pre-process the event data as in <code>matlab/DHP19/generate_DHP19/Generate_DHP19.m</code>​. This script will generate a bunch of event data ended with <code>.h5</code>​​. Then <code>src/dataset/pose7500.py</code>​ is used to turn <code>.h5</code>​ files into <code>.npy</code>​ files for faster dataset load. </p>]]></content>
      
      
        <tags>
            
            <tag> projects </tag>
            
        </tags>
      
    </entry>
    
  
  
</search>
